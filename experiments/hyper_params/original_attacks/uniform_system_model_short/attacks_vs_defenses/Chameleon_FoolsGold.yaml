resources:
  devices: "0"
  cpus_per_client: 1
  gpus_per_client: 0.1

# General setting
num_clients: 100
clients_per_round: 10
num_rounds: 2100
partitioning: 'dirichlet'
partitioning_hyperparam: 0.9

# Strategy
strategy:
  name: 'fedavg_bagdasaryan'
  server_lr: 10 # For this attack, this is to be chosen such that server_lr = num_clients / clients_per_round
  lr_scheduler:
    name: 'chameleon'
    target_lr: 0.2
    initial_lr: 0.001
    num_rounds: 1100

# Task configuration
dataset: 'cifar10'
model: 'resnet20'
batch_size: 64
optimizer:
  name: 'sgd'
  local_lr: 0.1
  momentum: 0.9
  weight_decay: 0.0005
lr_scheduler:
  name:
  step_size: 2
  gamma: 0.8
local_epochs: 2

# Adversary configuration
attacker:
  name: 'chameleon'
  contrastive_local_epochs: 10
  contrastive_optimizer:
    local_lr: 0.005
    momentum: 0.9
    weight_decay: 0.0005
  contrastive_lr_scheduler:
    milestones: [3, 5, 7, 9]
    gamma: 0.1
  contrastive_poison_ratio: 0.1875
  beta: 2
  gamma: 1 # This is the model replacement scaling rate - apparently, they do only do a data poisoning attack
  split_layer: 'layer3'
  norm_bound: 5
adversarial_optimizer:
  name: 'sgd'
  local_lr: 0.001
  momentum: 0.9
  weight_decay: 0.005
adversarial_lr_scheduler:
  name: 'multi_step'
  milestones: [0.2, 0.8]
  gamma: 0.005
local_epochs_malicious_clients: 3
compromised_clients: 0.1

# Backdoor configuration
backdoor:
  type: 'artificial_trigger'
  source_class: 1
  target_class: 2
  poison_ratio: 0.109375
  noise_level: 0.01
poisoning_scheduler:
  name: 'interval'
  start_round: 1000
  end_round: 1100

# Defense
defense:
  name: 'foolsgold'
  memory_size: 10
  importance: 'hard'

# Differential Privacy
differential_privacy:
  enabled: false
