resources:
  devices: "3"
  cpus_per_client: 1
  gpus_per_client: 0.1

# General setting
num_clients: 100
clients_per_round: 10
num_rounds: 205
partitioning: 'dirichlet'
partitioning_hyperparam: 0.9

# Strategy
strategy:
  name: 'fedavg'
  lr_scheduler:
    name: 'exp'
    gamma: 0.999

# Load trained model
load_benign_model:
    trained_rounds: 900
    experiment_descriptor: 'BenignTraining_0.1_decay'

# Task configuration
dataset: 'cifar10'
model: 'resnet20'
batch_size: 64
optimizer:
  name: 'sgd'
  local_lr: 0.1
  momentum: 0.9
  weight_decay: 0.0005
lr_scheduler:
  name:
local_epochs: 2

# Adversary configuration
attacker:
  name: 'darkfed'
  weight_scale: 1
  trigger_opacity: 1
  trigger_scale: 0.25
  cosine_layer: 'linear' # This has to correspond to the fully-connected layer of the employed network
  shadow_dataset: 'gtsrb'
adversarial_optimizer:
  name: 'sgd'
  local_lr: 0.005
  momentum: 0
  weight_decay: 0
adversarial_lr_scheduler:
  name: 'cosine_annealing'
  T_max: 2 # equal to local_epochs_malicious_clients
  eta_min: 1e-10
local_epochs_malicious_clients: 2
compromised_clients: 0.1

# Backdoor configuration
backdoor:
  type: 'artificial_trigger'
  source_class:
  target_class: 8
  poison_ratio: 0.1 # Value in config file is wrong. 0.1 is hardcoded in datafreenoise.py:L181
poisoning_scheduler:
  name: 'interval'
  start_round: 1000
  end_round: 1100

# Defense
defense:
  name: 'bulyan'
  f: 1

# Differential Privacy
differential_privacy:
  enabled: false
